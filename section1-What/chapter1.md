---
label: 绪论
layout: default
order: 50
icon: ":film_frames:"
---

![](/static/face/1.jpg)

## 1 自动驾驶简介

我们正处于未来自动驾驶的黎明时期。了解未来如何，常需回顾历史，所以让我们从此开始。

信息技术的真正开端始于上世纪60年代，当时Fairchild Semiconductor和英特尔(Intel)通过生产微处理器奠定了信息技术的基础，并顺便创建了硅谷。虽然微处理器技术极大地提高了我们的生产力，但公众对这些技术的了解有限。20世纪80年代，微软和苹果推出了图形用户界面，奠定了信息技术的第二层，实现了“家家有PC/Mac”的愿景。进入21世纪后，以谷歌为代表的互联网企业通过人与信息的连接，构筑了信息技术的第三层。例如，通过谷歌可以间接连接信息的提供人和信息的使用人。到了2010年后，Facebook、LinkedIn等社交网络公司奠定了信息技术的第四层，有效地将人类社会转移到了互联网上，让人们可以直接相互联系。在以互联网为基础的人类社会人口达到显著规模后，2015年前后，Uber和Airbnb的出现奠定了信息技术的第五层，为以互联网为基础的人类社会提供服务，形成了以互联网为基础的商业社会。虽然Uber和Airbnb为我们提供了通过互联网高效访问服务提供商的手段，但这些服务仍然是由人类提供的。  

### 1.1 技术概述

如图1.1所示，自动驾驶不是一项单一的技术，而是一个由许多子系统组成的高度复杂的子系统。我们把它分成三个主要部分:算法，包括探测、感知和决策(这需要对复杂情况进行推理);客户端系统，包括操作系统和硬件平台;云平台，包括高清地图、深度学习模型训练、仿真、数据存储。

算法子系统从传感器的原始数据中提取有意义的信息来理解所处的环境，并对其未来的行动做出决策。客户系统集成了这些算法，以满足实时和可靠性的要求。例如，如果摄像机以60hz的频率生成数据，客户端系统需要确保处理传输信息的最多不超过16ms完成。云平台提供自动驾驶汽车的离线计算和存储。通过云平台，我们能够测试新的算法，更新高清地图，训练更好的识别，跟踪和决策模型。  

### 1.2 算法

算法组件包括探测，即从传感器原始数据中提取有意义的信息; 感知，即定位车辆并了解当前环境; 决策，即采取行动，将车辆可靠和安全地送达目的地。  

#### 1.2.1 探测

通常，自动驾驶汽车由几个主要传感器组成。由于每一种传感器都有相应的优点和缺点，所以在自动驾驶中，必须通过多个传感器的数据组合来提高可靠性和安全性。常用的传感器如下：
>(1) GPS/IMU: GPS（全球卫星导航系统）/IMU（惯性测量单元）可以帮助自动驾驶车辆进行定位以高达200HZ的频率进行全球定位及惯导更新。GPS的定位精度很高，但更新频率往往只有10赫兹，因此不能提供实时的位置更新。IMU的误差随时间推移而累积，导致位置估计的精度变低。但IMU可以提供高达200HZ频率的位置更新，满足实时性的要求。通过结合GPS和IMU，我们可以为车辆提供准确实时的定位。<br>(2) LiDAR: LiDAR（激光雷达）用于测绘、定位和避障。它的工作原理是将光束反射到表面，并测量反射时间来测距。由于其精度高，激光雷达可以用来生成高清地图，在地图中定位移动的车辆，检测前方的障碍等。通常情况下，一个激光雷达装置，如Velodyne 64束激光器，以10hz的频率旋转，每秒约130万个读数。<br>(3) Cameras: 相机主要用于物体识别和跟踪任务,如车道检测、交通灯检测、行人检测等。为了提高自动驾驶车辆的安全性，现在通常在车辆全身安装8个或更多的1080p摄像头，这样可以使用摄像头来检测、识别和跟踪车辆前后和两侧的物体。以60HZ的频率计算，一辆车的相机每秒将产生大约1.8GB的原始数据。<br>(4) Radar and Sonar: 雷达和声纳系统是避障的最后一道防线。雷达和声纳得到的数据可以显示出距离车辆路径前面最近的物体的距离和速度。一旦我们发现一个物体在前方不远，就可能有碰撞的危险，那么自动驾驶车辆应刹车或转弯以避开障碍物。因此，雷达和声纳产生的数据不需要太多的处理，通常是直接给到控制处理器，也不需要通过主要的计算程序，来实现诸如转向、刹车或预紧安全带等“紧急”功能。

#### 1.2.2 感知

在感知环节，传感器的数据输入进来被用于车辆理解周边的环境。自动驾驶感知阶段的三个主要任务分别为定位、目标检测和目标跟踪。  

GPS/IMU可以用于定位，如上节所述，GPS提供相当准确的定位结果，但更新频率较低，而IMU提供快速更新，其代价是定位精度较低。因此，我们可以使用卡尔曼滤波技术结合两者的优点，提供准确和实时的位置更新。如图1.2所示，其工作原理如下:IMU每5ms更新一次车辆位置，但随着时间的推移误差会不断的累积。而每过100ms，IMU会接受到一个GPS测量得到的位置以纠正IMU的误差。使用该传播和更新模型，GPS/IMU组合可生成快速和精确的定位结果。尽管如此，我们也不能仅仅依靠这种组合进行定位，有以下原因:
>(1) 精度只有一米左右;<br>(2) GPS信号存在多路径效应，这意味着信号可能会被周边的建筑物反射，引入更多的噪声;<br>(3) GPS需要开阔的天顶视野以接受卫星传播的信号，导致其不能在隧道等室内环境中工作。<br> 

摄像头也可以用于定位。基于视觉的定位可以通过以下步骤实现:
>(1)通过对立体图像对进行三角定位，我们首先获得视差地图，可用于导出每个点的深度信息;<br>(2)通过匹配连续立体图像帧间的显著特征，建立不同帧间特征点之间的相关性。可以估计出过去两帧之间的运动;<br>(3)通过与已知地图上的显著特征进行比较，我们还可以得出车辆的当前位置。

然而，这种基于视觉的定位方法对照明条件要求很高，因此，仅使用这种方法是不可靠的。

这便是激光雷达方法使用粒子滤波技术的原因。激光雷达生成的点云数据提供了环境的“形状描述”，但这是很难区分出单独的点。通过使用粒子滤波器，将特定的观测形状与已知地图进行比较，以此减少不确定性。为了在得到的地图中定位出车辆的位置，我们可以应用粒子滤波将激光雷达测量与地图关联。粒子滤波可以实现10cm精度的实时定位，并在城市环境中有效。然而，激光雷达也存在技术相关的问题: 当空气中有很多悬浮颗粒时，比如雨滴和灰尘，测量结果可能会非常嘈杂。因此，如图1.4所示，为了实现可靠准确的定位，我们需要多源融合技术——将多个传感器的数据进行融合处理。

#### 1.2.3 目标识别与跟踪

起初，在自动驾驶汽车中，激光雷达主要用于行目标检测和跟踪任务，因为激光雷达可以提供非常精确的深度信息。然而，近年来，我们看到了深度学习技术的快速发展，它实现了显著的目标检测和跟踪精度。卷积神经网络(convolutional Neural Network, CNN)是深度神经网络(Deep Neural Network, DNN)的一种，被广泛应用于物体识别任务中。一般的CNN模型通常由以下几层组成：(1)卷积层包含不同的滤波器，以实现对输入图像提取不同的特征。每个滤波器包含一组“可学习的”参数（超参数），这些参数可在训练阶段之后导出。(2)激活层决定是否激活目标神经元。(3)池化层通过减小表示的空间大小来减少参数的数量，从而减少网络中的计算量。(4)全连接层将该层的神经元与上一层所有激活的神经元连接。

目标跟踪是指在目标运动过程中对其轨迹的自动估计。在利用目标识别技术识别出要跟踪的目标后，目标跟踪的目的是随后自动跟踪其轨迹。这项技术可以用于跟踪附近移动的车辆以及过马路的人，以确保当前的车辆不会与这些移动的物体相撞。近年来，与传统的计算机视觉技术相比，深度学习技术在目标跟踪方面显示出巨大的优势。具体来说，通过使用辅助自然图像，堆叠的自编码器（Auto-Encoder）可以脱机训练，学习通用的图像特征以使得对视角和车辆位置的变化估计更有稳健性。然后，利用离线训练得到的模型部署到自动驾驶车辆内进行在线跟踪。

#### 1.2.4 决策

在了解车辆环境的基础上，决策阶段可以生成一个安全的和实时有效的行动计划。

##### 行为预测

司机在开车导航时最害怕的情况之一是其他司机可能的横冲直撞和不按常理出牌。尤其在道路上有多条车道或车辆处于交通换乘点时。为确保车辆在这些环境中安全行驶，决策单元会生成附近车辆的预测，并根据这些预测决定行动计划。而为了实现预测的目的，会生成其他交通参与者可达位置集的随机模型，并将这些可达位置集与概率分布联系起来。

##### 路径规划

动态环境下保证自主灵敏的路径规划是一个非常复杂的问题，特别是当车辆需要充分利用其机动能力时。暴力但直接的方法是搜索所有可能的路径，并利用成本函数来确定最佳路径。然而，这需要大量的计算资源，并且可能无法实时交付给导航环节。为了克服确定性完备算法的计算复杂性，可以使用概率规划器来提供有效的实时路径规划。

#### 障碍躲避

由于安全是自动驾驶的首要问题，我们通常会采用至少两级的避障机制，以确保车辆不会与障碍物发生碰撞。第一级是主动避障，基于交通预测来实现。在运行时，交通预测机制生成碰撞时间或预测的最小距离等度量，并根据这些信息触发避障机制进行局部路径重新规划。如果主动机制失效，则触发第二级反应机制，利用雷达数据接管控制。一旦雷达发现前方有障碍物，它就会越过当前的车辆控制来躲避障碍物。
